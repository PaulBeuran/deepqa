{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.11 in /home/pbeuran/.local/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers in /home/pbeuran/.local/lib/python3.8/site-packages (4.19.2)\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
      "\u001b[K     |████████████████████████████████| 574 kB 22.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/pbeuran/.local/lib/python3.8/site-packages (from torch==1.11) (4.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (1.22.1)\n",
      "Requirement already satisfied: requests in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.0.0.tar.gz (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/pbeuran/.local/lib/python3.8/site-packages (from stanza) (3.20.1)\n",
      "Requirement already satisfied: six in /home/pbeuran/.local/lib/python3.8/site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pbeuran/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193002 sha256=f2ba39c5bfc065aae279bed1af2dbc61228ec33cdc462937c87bff48a815fdbb\n",
      "  Stored in directory: /home/pbeuran/.cache/pip/wheels/23/a5/a8/e74bad1ceced228b6ae94dcbacc5c67df6486fd1620714e7d1\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.0.0 stanza-1.4.0\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Mandatory : Run this cell and restart the notebook kernel right after\n",
    "#####################################################################\n",
    "!pip install torch==1.11 transformers stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content'\n",
      "/home/pbeuran/personal_repositories/deepqa/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "# Clone the repo content into\n",
    "cd /content\n",
    "rm -rf deepqa\n",
    "git clone -b model https://github.com/PaulBeuran/deepqa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "# Clone the repo content into\n",
    "cd /content\n",
    "rm -rf deepqa\n",
    "git clone -b model https://github.com/PaulBeuran/deepqa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'deepqa/notebooks/'\n",
      "/home/pbeuran/personal_repositories/deepqa/notebooks\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "%cd deepqa/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  822M  100  822M    0     0  4124k      0  0:03:24  0:03:24 --:--:-- 4146k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: word_encoders_configs/glove.6B.50d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.100d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.200d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "curl -O https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "unzip -o glove.6B.zip -d word_encoders_configs\n",
    "rm glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 00:36:05.538503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-30 00:36:05.538577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Dowload the SQuAD1.1 data\n",
    "curl -O https://data.deepai.org/squad1.1.zip\n",
    "unzip -o squad1.1.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:25:33.334467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-05 11:25:33.334539: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "deepqa_lib_path = str(pathlib.Path(os.getcwd()).parent.parent.absolute())\n",
    "sys.path.insert(0, deepqa_lib_path)\n",
    "\n",
    "from deepqa import preprocessing, tokenizer, model, wrapper, loss, metrics, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and dev data\n",
    "with open(\"data/train-v1.1.json\", \"rb\") as j:\n",
    "    train_data = json.load(j)[\"data\"]\n",
    "with open(\"data/dev-v1.1.json\", \"rb\") as j:\n",
    "    dev_data = json.load(j)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tcqa = preprocessing.tabularize_squad11_data(train_data)\n",
    "dev_tcqa = preprocessing.tabularize_squad11_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:25:36.658983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-05 11:25:36.659049: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-05 11:25:36.659075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-6LCD53E): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from spacy.lang.en import English\n",
    "import pickle\n",
    "from deepqa.utils import char_ranges_to_token_ranges\n",
    "\n",
    "class GLoVETokenizer():\n",
    "\n",
    "    def __init__(self, corpus=\"6B\", tokenize_char=False):\n",
    "\n",
    "        self.word_tokenizer = English().tokenizer\n",
    "        with open(f\"../word_encoders_configs/glove.{corpus}.50d.txt\", \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(\"\\n\", \"\").split(\" \") for line in lines]\n",
    "        word_vocab = [line[0] for line in lines]\n",
    "        self.word_vocab_id_mapping = {**dict(zip(word_vocab, range(len(word_vocab)))),\n",
    "                                      **{\"\": len(word_vocab) + 1}}\n",
    "        self.word_vocab_len = len(self.word_vocab_id_mapping)\n",
    "        self.tokenize_char = tokenize_char\n",
    "        if tokenize_char:\n",
    "            char_token_vocab_path = \"../tokenizers_configs\"\n",
    "            char_vocab = pickle.load(open(f\"{char_token_vocab_path}/bert-base-uncased.ctk\", \"rb\"))\n",
    "            self.char_vocab_len = len(char_vocab)\n",
    "            self.char_vocab_id_mapping = dict(zip(char_vocab, range(len(char_vocab))))\n",
    "\n",
    "\n",
    "    def __call__(self, texts, tokens_max_length, token_max_length, **kwargs):\n",
    "\n",
    "        tokenize_result = dict()\n",
    "\n",
    "        texts = [re.sub(r\" {2,}\", \"\", text) for text in texts]\n",
    "\n",
    "        inputs_tokens = [list(doc) for doc in self.word_tokenizer.pipe(texts)]\n",
    "\n",
    "        inputs_truncated = [len(input_tokens) > tokens_max_length\n",
    "                            for input_tokens in inputs_tokens]\n",
    "        inputs_tokens = [input_tokens[:min(len(input_tokens), tokens_max_length)] \n",
    "                         for input_tokens in inputs_tokens]\n",
    "        inputs_low_pad_tokens = [[str(input_token).lower() \n",
    "                                  for input_token in input_tokens] +\n",
    "                                 (tokens_max_length - len(input_tokens)) * [\"\"]\n",
    "                                for input_tokens in inputs_tokens]\n",
    "        tokenize_result[\"truncated\"] = torch.tensor(inputs_truncated)\n",
    "\n",
    "        inputs_ids = [[self.word_vocab_id_mapping.get(input_low_pad_token, \n",
    "                                                      self.word_vocab_len)\n",
    "                       for input_low_pad_token in input_low_pad_tokens]\n",
    "                      for input_low_pad_tokens in inputs_low_pad_tokens]\n",
    "        tokenize_result[\"input_ids\"] = torch.tensor(inputs_ids, dtype=torch.int32, \n",
    "                                                    device=\"cpu\")\n",
    "\n",
    "        offset_mappings = [[(input_token.idx, input_token.idx + len(input_token))\n",
    "                            for input_token in input_tokens] +\n",
    "                           ((tokens_max_length - len(input_tokens)) * [(0, 0)])\n",
    "                           for input_tokens in inputs_tokens]\n",
    "        tokenize_result[\"offset_mapping\"] = torch.tensor(offset_mappings, dtype=torch.int32, \n",
    "                                                         device=\"cpu\")\n",
    "\n",
    "        if self.tokenize_char:\n",
    "            inputs_tokens_char_ids = (\n",
    "                [[[self.char_vocab_id_mapping.get(char, self.char_vocab_len) \n",
    "                   for char in list(input_low_pad_token)] +\n",
    "                   ((token_max_length - len(input_low_pad_token)) *\n",
    "                    [self.char_vocab_len + 1])\n",
    "                  for input_low_pad_token in input_low_pad_tokens]\n",
    "                 for input_low_pad_tokens in inputs_low_pad_tokens]\n",
    "            )\n",
    "            tokenize_result[\"inputs_char_ids\"] = torch.tensor(inputs_tokens_char_ids, \n",
    "                                                              dtype=torch.int32, \n",
    "                                                              device=\"cpu\")\n",
    "        \n",
    "        return tokenize_result\n",
    "\n",
    "    def tokenize_qa_data(self, contexts, queries, answers,\n",
    "                         context_max_length, query_max_length, token_max_length):\n",
    "        contexts_tokens = self(contexts, context_max_length, token_max_length)\n",
    "        queries_tokens = self(queries, query_max_length, token_max_length)\n",
    "        answers_chars_range = [(answer[\"answer_start\"], \n",
    "                                answer[\"answer_start\"] + len(answer[\"text\"]))\n",
    "                               for answer in answers]\n",
    "        answers_tokens_range = char_ranges_to_token_ranges(answers_chars_range, \n",
    "                                                           contexts_tokens[\"offset_mapping\"],\n",
    "                                                           context_max_length)\n",
    "        return contexts_tokens, queries_tokens, answers_tokens_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_tokenizer = GLoVETokenizer(tokenize_char=True)\n",
    "\n",
    "context_max_length = 256\n",
    "query_max_length = 64\n",
    "token_max_length = 64\n",
    "\n",
    "train_tokens_cqa = glove_tokenizer.tokenize_qa_data(\n",
    "    *(train_tcqa[1:]), context_max_length, query_max_length, token_max_length\n",
    ")\n",
    "dev_tokens_cqa = glove_tokenizer.tokenize_qa_data(\n",
    "    *(dev_tcqa[1:]), context_max_length, query_max_length, token_max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, contexts_tokens, queries_tokens, answers_tokens_range,\n",
    "                 device = \"cpu\"):\n",
    "\n",
    "        to_remove = ~(contexts_tokens[\"truncated\"] | queries_tokens[\"truncated\"])\n",
    "        self.contexts_tokens = {k:v[to_remove] for k,v in contexts_tokens.items()}\n",
    "        self.queries_tokens = {k:v[to_remove] for k,v in queries_tokens.items()}\n",
    "        self.answers_tokens_range = answers_tokens_range[to_remove]\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"contexts_tokens\": {k:v[index].to(self.device)\n",
    "                                    for k,v in self.contexts_tokens.items()},\n",
    "                \"queries_tokens\": {k:v[index].to(self.device)\n",
    "                                    for k,v in self.queries_tokens.items()},\n",
    "                \"answers_tokens_range\": self.answers_tokens_range[index].to(self.device)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answers_tokens_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLoVEWordEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, corpus=\"6B\", embedding_size=50, char_encoder=None):\n",
    "        \n",
    "        super(GLoVEWordEncoder, self).__init__()\n",
    "        with open(f\"../word_encoders_configs/glove.{corpus}.{embedding_size}d.txt\", \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.replace(\"\\n\", \"\").split(\" \") for line in lines]\n",
    "        word_embeddings = torch.zeros((len(lines) + 2, embedding_size))\n",
    "        word_embeddings[:len(lines), :] = torch.tensor(\n",
    "            [[float(embedding) for embedding in line[1:]] for line in lines]\n",
    "        )\n",
    "        self.word_embeddings = torch.nn.Embedding.from_pretrained(word_embeddings,\n",
    "                                                                  padding_idx=len(lines) + 1)\n",
    "        self.char_encoder = char_encoder\n",
    "\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        word_embeddings = self.word_embeddings(tokens[\"input_ids\"])\n",
    "        return word_embeddings\n",
    "\n",
    "    def output_shape(self):\n",
    "        output_shape = self.word_embeddings.weight.shape[1]\n",
    "        if self.char_encoder is not None:\n",
    "            output_shape = output_shape + self.char_encoder.output_shape()\n",
    "        return self.word_embeddings.weight.shape[1]\n",
    "\n",
    "\n",
    "class CharCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 char_vocab_len,\n",
    "                 char_embedding_size, \n",
    "                 outs_channels,\n",
    "                 kernel_sizes):\n",
    "\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.char_encoder = torch.nn.Embedding(char_vocab_len + 3, \n",
    "                                               char_embedding_size, \n",
    "                                               char_vocab_len + 2)\n",
    "        self.in_channels = char_embedding_size\n",
    "        self.outs_channels = outs_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.conv1d_list = list()\n",
    "        for i, kernel_size in enumerate(kernel_sizes):\n",
    "            conv1d = torch.nn.Conv1d(char_embedding_size, outs_channels[i], kernel_size)\n",
    "            setattr(self, f\"conv{i+1}\", conv1d)\n",
    "            self.conv1d_list.append(conv1d)\n",
    "\n",
    "    def forward(self, char_tokens):\n",
    "\n",
    "        char_embeddings = self.char_encoder(char_tokens)\n",
    "\n",
    "        batch_size = char_embeddings.shape[0]\n",
    "        token_seq_size = char_embeddings.shape[1]\n",
    "        token_char_seq_size = char_embeddings.shape[2]\n",
    "        features_size = char_embeddings.shape[3]\n",
    "        \n",
    "        rav_char_embeddings = (char_embeddings.transpose(3, 2)\n",
    "                                              .reshape(batch_size * token_seq_size,\n",
    "                                                       features_size,\n",
    "                                                       token_char_seq_size))\n",
    "        rav_char_embeddings = torch.cat(\n",
    "            [torch.nn.Tanh()(conv1d(rav_char_embeddings)).max(dim=2)[0]\n",
    "             for conv1d in self.conv1d_list],\n",
    "             dim=1\n",
    "        ).reshape(batch_size, token_seq_size, -1)\n",
    "        return rav_char_embeddings\n",
    "\n",
    "    def output_shape(self):\n",
    "        return sum([conv1d.out_channels for conv1d in self.conv1d_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=0'>1</a>\u001b[0m glove_word_encoder \u001b[39m=\u001b[39m GLoVEWordEncoder(embedding_size\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=1'>2</a>\u001b[0m contextual_embedding_size \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=3'>4</a>\u001b[0m bidaf \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mBiDAF(glove_word_encoder, contextual_embedding_size, \u001b[39m0.2\u001b[39m)\n",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36mGLoVEWordEncoder.__init__\u001b[0;34m(self, corpus, embedding_size, char_encoder, char_vocab_len, char_embedding_size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=8'>9</a>\u001b[0m lines \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=9'>10</a>\u001b[0m word_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, embedding_size))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=10'>11</a>\u001b[0m word_embeddings[:\u001b[39mlen\u001b[39m(lines), :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=11'>12</a>\u001b[0m     [[\u001b[39mfloat\u001b[39m(embedding) \u001b[39mfor\u001b[39;00m embedding \u001b[39min\u001b[39;00m line[\u001b[39m1\u001b[39m:]] \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mfrom_pretrained(word_embeddings,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=14'>15</a>\u001b[0m                                                           padding_idx\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m char_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=8'>9</a>\u001b[0m lines \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=9'>10</a>\u001b[0m word_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, embedding_size))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=10'>11</a>\u001b[0m word_embeddings[:\u001b[39mlen\u001b[39m(lines), :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=11'>12</a>\u001b[0m     [[\u001b[39mfloat\u001b[39m(embedding) \u001b[39mfor\u001b[39;00m embedding \u001b[39min\u001b[39;00m line[\u001b[39m1\u001b[39m:]] \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mfrom_pretrained(word_embeddings,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=14'>15</a>\u001b[0m                                                           padding_idx\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m char_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=8'>9</a>\u001b[0m lines \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=9'>10</a>\u001b[0m word_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, embedding_size))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=10'>11</a>\u001b[0m word_embeddings[:\u001b[39mlen\u001b[39m(lines), :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=11'>12</a>\u001b[0m     [[\u001b[39mfloat\u001b[39;49m(embedding) \u001b[39mfor\u001b[39;00m embedding \u001b[39min\u001b[39;00m line[\u001b[39m1\u001b[39m:]] \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mfrom_pretrained(word_embeddings,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=14'>15</a>\u001b[0m                                                           padding_idx\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(lines) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000031vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m char_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "char_cnn = CharCNN(1371, 16, [100], [5])\n",
    "\n",
    "glove_word_encoder = GLoVEWordEncoder(embedding_size=200, char_encoder=char_cnn)\n",
    "contextual_embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf = model.BiDAF(glove_word_encoder, contextual_embedding_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/16 - Train] Loss: 11.075, Overlap F1: 0.015:   0%|          | 8/83944 [00:09<28:08:10,  1.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m bidaf_trainer \u001b[39m=\u001b[39m wrapper\u001b[39m.\u001b[39mQATrainWrapper(bidaf)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000034vscode-remote?line=1'>2</a>\u001b[0m bidaf_trainer\u001b[39m.\u001b[39;49mtrain(train_loader, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000034vscode-remote?line=2'>3</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000034vscode-remote?line=3'>4</a>\u001b[0m                     loss\u001b[39m=\u001b[39;49mloss\u001b[39m.\u001b[39;49mbi_cross_entropy,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#ch0000034vscode-remote?line=4'>5</a>\u001b[0m                     val_data_iter\u001b[39m=\u001b[39;49mdev_loader)\n",
      "File \u001b[0;32m~/personal_repositories/deepqa/wrapper.py:25\u001b[0m, in \u001b[0;36mQATrainWrapper.train\u001b[0;34m(self, train_data_iter, epochs, loss, val_data_iter)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_iter_tqdm):\n\u001b[1;32m     24\u001b[0m     contexts_tokens, queries_tokens, answers_tokens_range \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(batch\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m---> 25\u001b[0m     answers_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel([contexts_tokens, queries_tokens], \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     26\u001b[0m     answer_preds \u001b[39m=\u001b[39m answers_probs\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/personal_repositories/deepqa/model.py:80\u001b[0m, in \u001b[0;36mBiDAF.forward\u001b[0;34m(self, x, use_dropout)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m use_dropout \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_rate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     contexts_queries_attentions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mDropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_rate)(contexts_queries_attentions)\n\u001b[0;32m---> 80\u001b[0m answers_embeddings, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manswer_encoder(contexts_queries_attentions)\n\u001b[1;32m     81\u001b[0m answers_start_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manswer_start_decoder(\n\u001b[1;32m     82\u001b[0m     torch\u001b[39m.\u001b[39mcat([contexts_queries_attentions, answers_embeddings], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m use_dropout \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_rate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    763\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = QADataset(*train_tokens_cqa, \"cuda\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, 64)\n",
    "\n",
    "dev_dataset = QADataset(*dev_tokens_cqa, \"cuda\")\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, 64)\n",
    "\n",
    "bidaf_trainer = wrapper.QATrainWrapper(bidaf)\n",
    "bidaf_trainer.train(train_loader, \n",
    "                    epochs=16, \n",
    "                    loss=loss.bi_cross_entropy,\n",
    "                    val_data_iter=dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
