{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.11 in /home/pbeuran/.local/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers in /home/pbeuran/.local/lib/python3.8/site-packages (4.19.2)\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
      "\u001b[K     |████████████████████████████████| 574 kB 22.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/pbeuran/.local/lib/python3.8/site-packages (from torch==1.11) (4.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (1.22.1)\n",
      "Requirement already satisfied: requests in /home/pbeuran/.local/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.0.0.tar.gz (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/pbeuran/.local/lib/python3.8/site-packages (from stanza) (3.20.1)\n",
      "Requirement already satisfied: six in /home/pbeuran/.local/lib/python3.8/site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pbeuran/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pbeuran/.local/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193002 sha256=f2ba39c5bfc065aae279bed1af2dbc61228ec33cdc462937c87bff48a815fdbb\n",
      "  Stored in directory: /home/pbeuran/.cache/pip/wheels/23/a5/a8/e74bad1ceced228b6ae94dcbacc5c67df6486fd1620714e7d1\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.0.0 stanza-1.4.0\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Mandatory : Run this cell and restart the notebook kernel right after\n",
    "#####################################################################\n",
    "!pip install torch==1.11 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content'\n",
      "/home/pbeuran/personal_repositories/deepqa/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "# Clone the repo content into\n",
    "cd /content\n",
    "rm -rf deepqa\n",
    "git clone -b model https://github.com/PaulBeuran/deepqa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "# Clone the repo content into\n",
    "cd /content\n",
    "rm -rf deepqa\n",
    "git clone -b model https://github.com/PaulBeuran/deepqa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'deepqa/notebooks/'\n",
      "/home/pbeuran/personal_repositories/deepqa/notebooks\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Only use on Googgle Colab, uncomment if necessary\n",
    "#####################################################################\n",
    "%cd deepqa/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  822M  100  822M    0     0  4124k      0  0:03:24  0:03:24 --:--:-- 4146k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: word_encoders_configs/glove.6B.50d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.100d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.200d.txt  \n",
      "  inflating: word_encoders_configs/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "curl -O https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "unzip -o glove.6B.zip -d word_encoders_configs\n",
    "rm glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 00:36:05.538503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-30 00:36:05.538577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Dowload the SQuAD1.1 data\n",
    "curl -O https://data.deepai.org/squad1.1.zip\n",
    "unzip -o squad1.1.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_CPU = True\n",
    "TORCH_CUDA_IS_AVAILABLE = torch.cuda.is_available()\n",
    "USE_GPU = not USE_CPU and TORCH_CUDA_IS_AVAILABLE\n",
    "\n",
    "if USE_GPU:\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "deepqa_lib_path = str(pathlib.Path(os.getcwd()).parent.parent.absolute())\n",
    "sys.path.insert(0, deepqa_lib_path)\n",
    "\n",
    "from deepqa import utils, preprocessing, tokenizer, module, model, wrapper, loss, metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and dev data\n",
    "with open(\"data/train-v1.1.json\", \"rb\") as j:\n",
    "    train_data = json.load(j)[\"data\"]\n",
    "with open(\"data/dev-v1.1.json\", \"rb\") as j:\n",
    "    dev_data = json.load(j)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tcqa = preprocessing.tabularize_squad11_data(train_data)\n",
    "dev_tcqa = preprocessing.tabularize_squad11_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_tokenizer = tokenizer.GLoVETokenizer(tokenize_char=False)\n",
    "\n",
    "context_max_length = 300\n",
    "query_max_length = 40\n",
    "token_max_length = 40\n",
    "\n",
    "train_tokens_cqa = glove_tokenizer.tokenize_qa_data(\n",
    "    *(train_tcqa[1:]), context_max_length, query_max_length, token_max_length\n",
    ")\n",
    "dev_tokens_cqa = glove_tokenizer.tokenize_qa_data(\n",
    "    *(dev_tcqa[1:]), context_max_length, query_max_length, token_max_length\n",
    ")\n",
    "\n",
    "train_dataset = utils.QADataset(*train_tokens_cqa, \"cuda\" if USE_GPU else \"cpu\")\n",
    "dev_dataset = utils.QADataset(*dev_tokens_cqa, \"cuda\" if USE_GPU else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cnn = module.CharCNN(1371, 16, [100], [5])\n",
    "\n",
    "glove_word_encoder = module.GLoVEWordEncoder(embedding_size=200, char_encoder=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_embedding_size = 100\n",
    "\n",
    "bidaf = model.BiDAF(glove_word_encoder, contextual_embedding_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, 64)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 - Train - Loss: 11.396, Metrics: {'EM': 0.0, 'F1': 0.012}:   0%|          | 2/1345 [00:20<3:53:53, 10.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1 - Model.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bidaf_trainer \u001b[39m=\u001b[39m wrapper\u001b[39m.\u001b[39mQATrainWrapper(bidaf)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m bidaf_trainer\u001b[39m.\u001b[39;49mtrain(train_loader, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                     loss\u001b[39m=\u001b[39;49mloss\u001b[39m.\u001b[39;49mbi_cross_entropy,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/pbeuran/personal_repositories/deepqa/notebooks/SQuAD1.1%20-%20Model.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                     val_data_iter\u001b[39m=\u001b[39;49mdev_loader)\n",
      "File \u001b[0;32m~/personal_repositories/deepqa/wrapper.py:52\u001b[0m, in \u001b[0;36mQATrainWrapper.train\u001b[0;34m(self, train_data_iter, epochs, loss, metrics, val_data_iter)\u001b[0m\n\u001b[1;32m     50\u001b[0m loss_batch \u001b[39m=\u001b[39m loss(answers_probs, answers_tokens_range)\n\u001b[1;32m     51\u001b[0m loss_step \u001b[39m=\u001b[39m loss_batch\u001b[39m.\u001b[39mmean()\n\u001b[0;32m---> 52\u001b[0m loss_step\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     54\u001b[0m metrics_batch_dict \u001b[39m=\u001b[39m {k : metric(answer_preds, answers_tokens_range)\n\u001b[1;32m     55\u001b[0m                       \u001b[39mfor\u001b[39;00m k,metric \u001b[39min\u001b[39;00m metrics\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bidaf_trainer = wrapper.QATrainWrapper(bidaf)\n",
    "bidaf_trainer.train(train_loader, \n",
    "                    epochs=2, \n",
    "                    loss=loss.bi_cross_entropy,\n",
    "                    val_data_iter=dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
